{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TF-IDF and Bag-of-Words Corpus\n",
        "\n",
        "This notebook defines a 50-document corpus for TF-IDF and bag-of-words experiments.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(50, 'The cat sleeps on the warm window ledge.')"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "doc_ids = [\n",
        "    \"doc01\",\n",
        "    \"doc02\",\n",
        "    \"doc03\",\n",
        "    \"doc04\",\n",
        "    \"doc05\",\n",
        "    \"doc06\",\n",
        "    \"doc07\",\n",
        "    \"doc08\",\n",
        "    \"doc09\",\n",
        "    \"doc10\",\n",
        "    \"doc11\",\n",
        "    \"doc12\",\n",
        "    \"doc13\",\n",
        "    \"doc14\",\n",
        "    \"doc15\",\n",
        "    \"doc16\",\n",
        "    \"doc17\",\n",
        "    \"doc18\",\n",
        "    \"doc19\",\n",
        "    \"doc20\",\n",
        "    \"doc21\",\n",
        "    \"doc22\",\n",
        "    \"doc23\",\n",
        "    \"doc24\",\n",
        "    \"doc25\",\n",
        "    \"doc26\",\n",
        "    \"doc27\",\n",
        "    \"doc28\",\n",
        "    \"doc29\",\n",
        "    \"doc30\",\n",
        "    \"doc31\",\n",
        "    \"doc32\",\n",
        "    \"doc33\",\n",
        "    \"doc34\",\n",
        "    \"doc35\",\n",
        "    \"doc36\",\n",
        "    \"doc37\",\n",
        "    \"doc38\",\n",
        "    \"doc39\",\n",
        "    \"doc40\",\n",
        "    \"doc41\",\n",
        "    \"doc42\",\n",
        "    \"doc43\",\n",
        "    \"doc44\",\n",
        "    \"doc45\",\n",
        "    \"doc46\",\n",
        "    \"doc47\",\n",
        "    \"doc48\",\n",
        "    \"doc49\",\n",
        "    \"doc50\"\n",
        "]\n",
        "\n",
        "\n",
        "corpus = [\n",
        "    \"The cat sleeps on the warm window ledge.\",\n",
        "    \"A dog chases a red ball across the yard.\",\n",
        "    \"The sun rises early in summer and sets late.\",\n",
        "    \"Rain falls softly on the quiet city streets.\",\n",
        "    \"Fresh bread smells good in the morning.\",\n",
        "    \"A chef slices tomatoes and stirs a soup.\",\n",
        "    \"Coffee brews while the newspaper rustles.\",\n",
        "    \"The runner ties her shoes before the race.\",\n",
        "    \"A cyclist rides uphill with steady effort.\",\n",
        "    \"The gym opens at six for early workouts.\",\n",
        "    \"A teacher explains math with clear examples.\",\n",
        "    \"Students take notes during a history lecture.\",\n",
        "    \"The library is silent except for turning pages.\",\n",
        "    \"A musician practices scales on the piano.\",\n",
        "    \"The guitarist tunes strings before the show.\",\n",
        "    \"A painter mixes blue and yellow into green.\",\n",
        "    \"The gallery displays modern art and sculpture.\",\n",
        "    \"The movie starts at eight with no previews.\",\n",
        "    \"Popcorn and soda spill on the theater floor.\",\n",
        "    \"A novelist edits a chapter late at night.\",\n",
        "    \"The phone battery dies during a long call.\",\n",
        "    \"A laptop boots slowly after a system update.\",\n",
        "    \"The app crashes when the network is weak.\",\n",
        "    \"A router blinks as data moves through the home.\",\n",
        "    \"The server logs show errors and retries.\",\n",
        "    \"The farmer plants seeds before spring rain.\",\n",
        "    \"A tractor moves across the field in straight lines.\",\n",
        "    \"Bees collect pollen from bright flowers.\",\n",
        "    \"The garden grows tomatoes, basil, and peppers.\",\n",
        "    \"A storm knocks branches onto the road.\",\n",
        "    \"The traveler packs light for a weekend trip.\",\n",
        "    \"A train arrives late at the busy station.\",\n",
        "    \"The plane lands smoothly after a long flight.\",\n",
        "    \"A taxi driver knows every shortcut downtown.\",\n",
        "    \"The hotel lobby smells of clean linen.\",\n",
        "    \"The chef prepares a spicy curry for dinner.\",\n",
        "    \"A baker decorates a cake with fresh berries.\",\n",
        "    \"The waiter refills water without being asked.\",\n",
        "    \"The menu lists soup, salad, and sandwiches.\",\n",
        "    \"A cyclist repairs a flat tire on the trail.\",\n",
        "    \"The coach outlines strategy before the match.\",\n",
        "    \"Fans cheer loudly as the team scores.\",\n",
        "    \"The referee blows the whistle to stop play.\",\n",
        "    \"A swimmer practices laps in the pool.\",\n",
        "    \"The hiker checks a map at the trailhead.\",\n",
        "    \"A camper lights a small fire for warmth.\",\n",
        "    \"The lake is calm at sunrise with light fog.\",\n",
        "    \"A photographer captures birds in flight.\",\n",
        "    \"The market sells apples, rice, and tea.\",\n",
        "    \"The cashier scans items and prints a receipt.\"\n",
        "]\n",
        "\n",
        "\n",
        "# Quick preview\n",
        "len(corpus), corpus[0]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac2b8ba9",
      "metadata": {},
      "source": [
        "## Preprocessing\n",
        "\n",
        "Lowercase, remove punctuation, and optionally drop simple stopwords.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "4fcf551a",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['cat', 'sleeps', 'warm', 'window', 'ledge'],\n",
              " ['dog', 'chases', 'red', 'ball', 'across', 'yard'],\n",
              " ['sun', 'rises', 'early', 'summer', 'sets', 'late']]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "STOPWORDS = {\n",
        "    'a', 'an', 'and', 'are', 'as', 'at', 'be', 'but', 'by', 'for',\n",
        "    'from', 'in', 'is', 'it', 'its', 'not', 'of', 'on', 'or', 'that',\n",
        "    'the', 'this', 'to', 'was', 'were', 'with'\n",
        "}\n",
        "\n",
        "def preprocess(text, remove_stopwords=True):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
        "    tokens = text.split()\n",
        "    if remove_stopwords:\n",
        "        tokens = [t for t in tokens if t not in STOPWORDS]\n",
        "    return tokens\n",
        "\n",
        "tokenized_corpus = [preprocess(doc) for doc in corpus]\n",
        "tokenized_corpus[:3]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8015b33e",
      "metadata": {},
      "source": [
        "## Bag of Words (manual)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "257df9ad",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'cat': 1, 'ledge': 1, 'sleeps': 1, 'warm': 1, 'window': 1}"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab = sorted({token for doc in tokenized_corpus for token in doc})\n",
        "vocab_index = {token: i for i, token in enumerate(vocab)}\n",
        "\n",
        "bow_matrix = []\n",
        "for doc in tokenized_corpus:\n",
        "    counts = Counter(doc)\n",
        "    row = [0] * len(vocab)\n",
        "    for token, count in counts.items():\n",
        "        row[vocab_index[token]] = count\n",
        "    bow_matrix.append(row)\n",
        "\n",
        "# Nonzero terms for the first document\n",
        "doc0_counts = {token: count for token, count in zip(vocab, bow_matrix[0]) if count}\n",
        "doc0_counts\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4fb90b6d",
      "metadata": {},
      "source": [
        "## TF-IDF (manual)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "338f1fe6",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('cat', 0.8477356904328762),\n",
              " ('ledge', 0.8477356904328762),\n",
              " ('sleeps', 0.8477356904328762),\n",
              " ('warm', 0.8477356904328762),\n",
              " ('window', 0.8477356904328762)]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import math\n",
        "\n",
        "N = len(tokenized_corpus)\n",
        "df = Counter()\n",
        "for doc in tokenized_corpus:\n",
        "    for token in set(doc):\n",
        "        df[token] += 1\n",
        "\n",
        "def idf(term):\n",
        "    return math.log((N + 1) / (df[term] + 1)) + 1\n",
        "\n",
        "tfidf_matrix = []\n",
        "for doc in tokenized_corpus:\n",
        "    counts = Counter(doc)\n",
        "    doc_len = len(doc)\n",
        "    row = []\n",
        "    for term in vocab:\n",
        "        tf = counts[term] / doc_len if doc_len else 0.0\n",
        "        row.append(tf * idf(term))\n",
        "    tfidf_matrix.append(row)\n",
        "\n",
        "def top_terms(doc_index, k=5):\n",
        "    scores = tfidf_matrix[doc_index]\n",
        "    pairs = sorted(zip(vocab, scores), key=lambda x: x[1], reverse=True)\n",
        "    return pairs[:k]\n",
        "\n",
        "top_terms(0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4d1f784",
      "metadata": {},
      "source": [
        "## Cosine similarity\n",
        "\n",
        "Compute cosine similarity between documents using the manual BoW and TF-IDF matrices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "eaae4b42",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([('doc02', 0.0),\n",
              "  ('doc03', 0.0),\n",
              "  ('doc04', 0.0),\n",
              "  ('doc05', 0.0),\n",
              "  ('doc06', 0.0)],\n",
              " [('doc02', 0.0),\n",
              "  ('doc03', 0.0),\n",
              "  ('doc04', 0.0),\n",
              "  ('doc05', 0.0),\n",
              "  ('doc06', 0.0)])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import math\n",
        "\n",
        "def cosine_sim(v1, v2):\n",
        "    dot = sum(a * b for a, b in zip(v1, v2))\n",
        "    norm1 = math.sqrt(sum(a * a for a in v1))\n",
        "    norm2 = math.sqrt(sum(b * b for b in v2))\n",
        "    return dot / (norm1 * norm2) if norm1 and norm2 else 0.0\n",
        "\n",
        "def cosine_matrix(matrix):\n",
        "    sims = []\n",
        "    for i in range(len(matrix)):\n",
        "        row = []\n",
        "        for j in range(len(matrix)):\n",
        "            row.append(cosine_sim(matrix[i], matrix[j]))\n",
        "        sims.append(row)\n",
        "    return sims\n",
        "\n",
        "def top_similar(doc_index, matrix, k=5):\n",
        "    sims = []\n",
        "    for i in range(len(matrix)):\n",
        "        if i == doc_index:\n",
        "            continue\n",
        "        sims.append((doc_ids[i], cosine_sim(matrix[doc_index], matrix[i])))\n",
        "    sims.sort(key=lambda x: x[1], reverse=True)\n",
        "    return sims[:k]\n",
        "\n",
        "bow_cosine = cosine_matrix(bow_matrix)\n",
        "tfidf_cosine = cosine_matrix(tfidf_matrix)\n",
        "\n",
        "top_similar(0, bow_matrix, k=5), top_similar(0, tfidf_matrix, k=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7ff7e2b",
      "metadata": {},
      "source": [
        "## Optional: scikit-learn vectorizers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "f865a7d0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "scikit-learn not installed. Run: pip install scikit-learn\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "except ImportError:\n",
        "    print('scikit-learn not installed. Run: pip install scikit-learn')\n",
        "else:\n",
        "    bow = CountVectorizer().fit_transform(corpus)\n",
        "    tfidf = TfidfVectorizer().fit_transform(corpus)\n",
        "    bow.shape, tfidf.shape\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
